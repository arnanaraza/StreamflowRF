#  df <- df[ , !(names(df) %in% 'date')]
#prepare train-test data
train <- subset(df, df$C.bname != basin)
train <- train[ , !(names(train) %in% c('date','C.bname'))]
train[] <- sapply(train, as.numeric)
test <- subset(df, df$C.bname == basin)
date <- test$date
test <- test[ , !(names(test) %in% c('date','C.bname'))]
test[] <- sapply(test, as.numeric)
}
#model training and testing including bias correction
RF <- ranger(train$O.obs ~ ., data=train[,-17], importance='permutation', mtry=15, keep.inbag=T) #should be re-run
RF
val.rf <- predict(RF, test[-17], type='se')
train$O.obs <-  train$O.obs - RF$predictions #bias
RF1 <-  ranger(train$O.obs ~ ., data=train[,-17], importance='permutation',mtry=15, keep.inbag = T)
val.rf.bc <- predict(RF1, test[-17], type='se')
val.rf$predictions.bc <- val.rf$predictions + val.rf.bc$predictions
val.rf$predictions.bc <- ifelse(val.rf$predictions.bc < 0 ,val.rf$predictions,
val.rf$predictions.bc)
val.rf$se.bc <- val.rf$se - val.rf.bc$se
val.rf$se.bc <- ifelse(val.rf$se.bc < 0 ,val.rf$se, val.rf$se.bc)
val.join <- data.frame(cbind(test$O.obs,val.rf$predictions.bc,
val.rf$predictions,val.rf$se.bc, val.rf$se))
val.join <- cbind(val.join, as.Date(date))
rm(RF,RF1)
#plot regression graphs
names (val.join) <- c('observed','predicted_bc','predicted','se_bc', 'se', 'date')
setwd(predDir)
write.csv(val.join, paste0(basin,'_',RFS,'_',td,'_pred.csv'), row.names=F)
setwd(mainDir)
return(val.join)
gc()
}
be=predTest(0.4,each.VT[[7]], SW.list[[7]], 'shed',predDir)
summary(lm(predicted~observed,be))
summary(lm(predicted_bc~observed,be))
summary(lm(predicted_bc~observed,be))
be=predTest(0.4,each.VT[[1]], SW.list[[1]], 'shed',predDir)
summary(lm(predicted~observed,be))
summary(lm(predicted_bc~observed,be))
be=predTest(0.4,each.VT[[2]], SW.list[[2]], 'shed',predDir)
summary(lm(predicted~observed,be))
summary(lm(predicted_bc~observed,be))
# Function to predict using RF model then
predTest <- function (td=0.6, df=mrb.VT, basin='mrb_s', RFS='all',predDir) {
dir.create(predDir, showWarnings = FALSE)
#prepare training-test data
set.seed(123)
if (td < 1 & td != 0.5){
#prepare train-test data
#    train <- subset(df, df$C.bname != basin)
#   train.b <- subset(df, df$C.bname == basin)
train.b <- df
samp <- floor((1-td)*nrow(train.b))
train_ind <- sample(seq_len(nrow(train.b)), size = samp)
#train.b1 <- train.b[-train_ind,] #
train <- train.b[-train_ind,] #
#train <- rbind(train,train.b1)
train <- train[ , !(names(train) %in% c('date','C.bname'))]
train[] <- sapply(train, as.numeric)
#test data
train.b <- read.csv(paste0(mainDir, '_Results/intermediate/VT/', basin, '.csv'))
#  train.b <- subset(df, df$C.bname == basin)
samp <- floor((1-td)*nrow(train.b))
train_ind <- sample(seq_len(nrow(train.b)), size = samp)
test <- train.b[train_ind,]
date <- test$date
test <- test[ , !(names(test) %in% c('date','C.bname'))]
test[] <- sapply(test, as.numeric)
if(RFS=='shed'){
train <- train.b[-train_ind,]
train <- train[ , !(names(train) %in% c('date','C.bname'))]
train[] <- sapply(train, as.numeric)
}
}else if (td == 0.5){
#prepare train-test data
samp <- floor((1-0.5)*nrow(df)) #50% train
train_ind <- sample(seq_len(nrow(df)), size = samp)
train <- df[-train_ind,] #
train <- train[ , !(names(train) %in% c('date','C.bname'))]
train[] <- sapply(train, as.numeric)
print(nrow(train))
test <- subset(df, df$C.bname == basin)
samp <- floor((1-0.5)*nrow(test))
train_ind <- sample(seq_len(nrow(test)), size = samp)
test <- test[train_ind,]
date <- test$date
test <- test[ , !(names(test) %in% c('date','C.bname'))]
test[] <- sapply(test, as.numeric)
print(nrow(test))
}else{
#  df <- df[ , !(names(df) %in% 'date')]
#prepare train-test data
train <- subset(df, df$C.bname != basin)
train <- train[ , !(names(train) %in% c('date','C.bname'))]
train[] <- sapply(train, as.numeric)
test <- subset(df, df$C.bname == basin)
date <- test$date
test <- test[ , !(names(test) %in% c('date','C.bname'))]
test[] <- sapply(test, as.numeric)
}
#model training and testing including bias correction
RF <- ranger(train$O.obs ~ ., data=train[,-17], importance='permutation', mtry=15, keep.inbag=T) #should be re-run
RF
val.rf <- predict(RF, test[-17], type='se')
train$O.obs <-  train$O.obs - RF$predictions #bias
RF1 <-  ranger(train$O.obs ~ ., data=train[,-17], importance='permutation',mtry=15, keep.inbag = T)
val.rf.bc <- predict(RF1, test[-17], type='se')
val.rf$predictions.bc <- val.rf$predictions - ( val.rf.bc$predictions - val.rf$predictions)
val.rf$predictions.bc <- ifelse(val.rf$predictions.bc < 0 ,val.rf$predictions,
val.rf$predictions.bc)
val.rf$se.bc <- val.rf$se - val.rf.bc$se
val.rf$se.bc <- ifelse(val.rf$se.bc < 0 ,val.rf$se, val.rf$se.bc)
val.join <- data.frame(cbind(test$O.obs,val.rf$predictions.bc,
val.rf$predictions,val.rf$se.bc, val.rf$se))
val.join <- cbind(val.join, as.Date(date))
rm(RF,RF1)
#plot regression graphs
names (val.join) <- c('observed','predicted_bc','predicted','se_bc', 'se', 'date')
setwd(predDir)
write.csv(val.join, paste0(basin,'_',RFS,'_',td,'_pred.csv'), row.names=F)
setwd(mainDir)
return(val.join)
gc()
}
be=predTest(0.4,each.VT[[2]], SW.list[[2]], 'shed',predDir)
summary(lm(predicted~observed,be))
summary(lm(predicted_bc~observed,be))
be=predTest(0.4,each.VT[[5]], SW.list[[5]], 'shed',predDir)
summary(lm(predicted~observed,be))
summary(lm(predicted_bc~observed,be))
be=predTest(0.4,each.VT[[7]], SW.list[[7]], 'shed',predDir)
summary(lm(predicted~observed,be))
summary(lm(predicted_bc~observed,be))
be=predTest(0.4,each.VT[[11]], SW.list[[11]], 'shed',predDir)
summary(lm(predicted~observed,be))
summary(lm(predicted_bc~observed,be))
be=predTest(0.4,each.VT[[21]], SW.list[[21]], 'shed',predDir)
summary(lm(predicted~observed,be))
summary(lm(predicted_bc~observed,be))
be=predTest(0.4,each.VT[[3]], SW.list[[3]], 'shed',predDir)
summary(lm(predicted~observed,be))
summary(lm(predicted_bc~observed,be))
View(be)
# Function to predict using RF model then
predTest <- function (td=0.6, df=mrb.VT, basin='mrb_s', RFS='all',predDir) {
dir.create(predDir, showWarnings = FALSE)
#prepare training-test data
set.seed(123)
if (td < 1 & td != 0.5){
#prepare train-test data
#    train <- subset(df, df$C.bname != basin)
#   train.b <- subset(df, df$C.bname == basin)
train.b <- df
samp <- floor((1-td)*nrow(train.b))
train_ind <- sample(seq_len(nrow(train.b)), size = samp)
#train.b1 <- train.b[-train_ind,] #
train <- train.b[-train_ind,] #
#train <- rbind(train,train.b1)
train <- train[ , !(names(train) %in% c('date','C.bname'))]
train[] <- sapply(train, as.numeric)
#test data
train.b <- read.csv(paste0(mainDir, '_Results/intermediate/VT/', basin, '.csv'))
#  train.b <- subset(df, df$C.bname == basin)
samp <- floor((1-td)*nrow(train.b))
train_ind <- sample(seq_len(nrow(train.b)), size = samp)
test <- train.b[train_ind,]
date <- test$date
test <- test[ , !(names(test) %in% c('date','C.bname'))]
test[] <- sapply(test, as.numeric)
if(RFS=='shed'){
train <- train.b[-train_ind,]
train <- train[ , !(names(train) %in% c('date','C.bname'))]
train[] <- sapply(train, as.numeric)
}
}else if (td == 0.5){
#prepare train-test data
samp <- floor((1-0.5)*nrow(df)) #50% train
train_ind <- sample(seq_len(nrow(df)), size = samp)
train <- df[-train_ind,] #
train <- train[ , !(names(train) %in% c('date','C.bname'))]
train[] <- sapply(train, as.numeric)
print(nrow(train))
test <- subset(df, df$C.bname == basin)
samp <- floor((1-0.5)*nrow(test))
train_ind <- sample(seq_len(nrow(test)), size = samp)
test <- test[train_ind,]
date <- test$date
test <- test[ , !(names(test) %in% c('date','C.bname'))]
test[] <- sapply(test, as.numeric)
print(nrow(test))
}else{
#  df <- df[ , !(names(df) %in% 'date')]
#prepare train-test data
train <- subset(df, df$C.bname != basin)
train <- train[ , !(names(train) %in% c('date','C.bname'))]
train[] <- sapply(train, as.numeric)
test <- subset(df, df$C.bname == basin)
date <- test$date
test <- test[ , !(names(test) %in% c('date','C.bname'))]
test[] <- sapply(test, as.numeric)
}
#model training and testing including bias correction
RF <- ranger(train$O.obs ~ ., data=train[,-17], importance='permutation', mtry=15, keep.inbag=T) #should be re-run
RF
val.rf <- predict(RF, test[-17], type='se')
train$O.obs <-  RF$predictions - train$O.obs #bias
RF1 <-  ranger(train$O.obs ~ ., data=train[,-17], importance='permutation',mtry=15, keep.inbag = T)
val.rf.bc <- predict(RF1, test[-17], type='se')
val.rf$predictions.bc <- val.rf$predictions - val.rf.bc$predictions
val.rf$predictions.bc <- ifelse(val.rf$predictions.bc < 0 ,val.rf$predictions,
val.rf$predictions.bc)
val.rf$se.bc <- val.rf$se - val.rf.bc$se
val.rf$se.bc <- ifelse(val.rf$se.bc < 0 ,val.rf$se, val.rf$se.bc)
val.join <- data.frame(cbind(test$O.obs,val.rf$predictions.bc,
val.rf$predictions,val.rf$se.bc, val.rf$se))
val.join <- cbind(val.join, as.Date(date))
rm(RF,RF1)
#plot regression graphs
names (val.join) <- c('observed','predicted_bc','predicted','se_bc', 'se', 'date')
setwd(predDir)
write.csv(val.join, paste0(basin,'_',RFS,'_',td,'_pred.csv'), row.names=F)
setwd(mainDir)
return(val.join)
gc()
}
be=predTest(0.4,each.VT[[3]], SW.list[[3]], 'shed',predDir)
df.all=all.df1
df.pca=pca.df1
df.shed=shed.df1
df.basin=basin.df1
head(df.all)
df1=all.df1[[1]]
df1 <- as.data.frame(df1 %>% group_by(month=month(df1$date)) %>%
summarise(observed=mean(observed), predicted=mean(predicted),
se=mean(se), bias=mean(observed-predicted)/se))
head(df1)
df1
df1 <- as.data.frame(df1 %>% group_by(month=month(df1$date)) %>%
summarise(observed=mean(observed), predicted=mean(predicted),
se=mean(se), bias=mean(observed-predicted)/se),
bias_bc=mean(observed-predicted_bc)/se)
df1 <- as.data.frame(df1 %>% group_by(month=month(df1$date)) %>%
summarise(observed=mean(observed), predicted=mean(predicted),
se=mean(se), bias=mean(observed-predicted)/se,
bias_bc=mean(observed-predicted_bc)/se)
df2 <- as.data.frame(df2 %>% group_by(month=month(df2$date)) %>%
summarise(observed=mean(observed), predicted=mean(predicted),
se=mean(se), bias=mean(observed-predicted)/se))
df3 <- as.data.frame(df3 %>% group_by(month=month(df3$date)) %>%
summarise(observed=mean(observed), predicted=mean(predicted),
se=mean(se), bias=mean(observed-predicted)/se))
df4 <- as.data.frame(df4 %>% group_by(month=month(df4$date)) %>%
summarise(observed=mean(observed), predicted=mean(predicted),
se=mean(se), bias=mean(observed-predicted)/se))
df1$method <- 'PCA-clustered'
df2$method <- 'Basin-clustered'
df3$method <- 'One-clustered'
df4$method <- 'Watershed-level'
df <- rbind(df1,df2, df3, df4)
df1 <- rbind(df11,df22, df33, df44)
names(df) <- c('month', 'observed', 'predicted', 'Uncertainty','SR', 'method')
cols <- c("red", "blue")
if(best == 1){
df
}
p <- ggplot(df, aes(x=month, y=SR)) +
scale_colour_manual(name="RF models", values=cols,limits=c('PCA-clustered', 'Basin-clustered',
'One-clustered', 'Watershed-level')) +
geom_point(aes(colour = method), size=2.5)+
theme_bw()+theme(legend.position = "none")+ggtitle(shed_name)+
scale_x_continuous("Month", breaks=c(1:12)) +
scale_y_continuous("Standardized residuals",limits=c(-2.2,2.2)) +
geom_hline(yintercept=0, linetype="dashed", color = "red", size=0.75) +
theme(axis.title.x=element_blank(),
axis.title.y=element_blank(),
axis.ticks.x=element_blank(),
text = element_text(size=15))
return(p)
}
boxplt <- lapply(1:21, function(x) BoxPlt1(df.pca[[x]], df.basin[[x]], df.all[[x]],
df.shed[[x]],SW.list[[x]], 'default'))
boxplt1 <- lapply(1:21, function(x) BoxPlt1(df.pca[[x]], df.basin[[x]], df.all[[x]],
df.shed[[x]],SW.list[[x]], 'bc'))
ggsave( multiplot(boxplt[[1]], boxplt[[2]],boxplt[[3]], boxplt[[4]], boxplt[[5]],
boxplt[[6]], boxplt[[7]],boxplt[[8]], boxplt[[9]], boxplt[[10]],
boxplt[[11]], boxplt[[12]],boxplt[[13]], boxplt[[14]], boxplt[[15]],
boxplt[[16]], boxplt[[17]],boxplt[[18]], boxplt[[19]], boxplt[[20]],
boxplt[[21]],cols=3),filename='PaperFigure_BiasShed.png',device='png',
dpi=600, width = 8, height = 16, units='in' )
ggsave( multiplot(boxplt1[[1]], boxplt1[[2]],boxplt1[[3]], boxplt1[[4]], boxplt1[[5]],
boxplt1[[6]], boxplt1[[7]],boxplt1[[8]], boxplt1[[9]], boxplt1[[10]],
boxplt1[[11]], boxplt1[[12]],boxplt1[[13]], boxplt1[[14]], boxplt1[[15]],
boxplt1[[16]], boxplt1[[17]],boxplt1[[18]], boxplt1[[19]], boxplt1[[20]],
boxplt1[[21]],cols=3),filename='PaperFigure_BiasShedBC.png',device='png',
dpi=600, width = 8, height = 16, units='in' )
df1 <- as.data.frame(df1 %>% group_by(month=month(df1$date)) %>%
summarise(observed=mean(observed), predicted=mean(predicted),
se=mean(se), bias=mean(observed-predicted)/se,
bias_bc=mean(observed-predicted_bc)/se))
df1
df.all=all.df1[[1]]
df1 <- as.data.frame(df1 %>% group_by(month=month(df1$date)) %>%
summarise(observed=mean(observed), predicted=mean(predicted),
se=mean(se), bias=mean(observed-predicted)/se,
bias_bc=mean(observed-predicted_bc)/se))
df.all=all.df1[[1]]
df1=all.df1[[1]]
head(df1)
View(df1)
df1 <- as.data.frame(df1 %>% group_by(month=month(df1$date)) %>%
summarise(observed=mean(observed), predicted=mean(predicted),
se=mean(se), bias=mean(observed-predicted)/se,
bias_bc=mean(observed-predicted_bc)/se))
View(df1)
df1=all.df1[[1]]
df1 <- as.data.frame(df1 %>% group_by(month=month(df1$date)) %>%
summarise(observed=mean(observed), predicted=mean(predicted),
se=mean(se), bias=mean(observed-predicted)/se,
bias_bc=mean(observed-predicted_bc)/se_bc))
df1=all.df1[[1]]
df1 <- as.data.frame(df1 %>% group_by(month=month(df1$date)) %>%
summarise(observed=mean(observed), predicted=mean(predicted),
se=mean(se), bias=mean(observed-predicted)/se,
bias_bc=mean(observed-predicted_bc)/mean(se_bc)))
df1=all.df1[[1]]
df1 <- as.data.frame(df1 %>% group_by(month=month(df1$date)) %>%
summarise(observed=mean(observed), predicted=mean(predicted),
se=mean(se), bias=mean(observed-predicted)/se,
bias_bc=mean(observed-predicted_bc)/se))
df1$method <- 'PCA-clustered'
BoxPlt1 <- function(df1,df2,df3,df4,shed_name,){
df1 <- as.data.frame(df1 %>% group_by(month=month(df1$date)) %>%
summarise(observed=mean(observed), predicted=mean(predicted),
se=mean(se), bias=mean(observed-predicted)/se,
bias_bc=mean(observed-predicted_bc)/se))
df2 <- as.data.frame(df2 %>% group_by(month=month(df2$date)) %>%
summarise(observed=mean(observed), predicted=mean(predicted),
se=mean(se), bias=mean(observed-predicted)/se))
df3 <- as.data.frame(df3 %>% group_by(month=month(df3$date)) %>%
summarise(observed=mean(observed), predicted=mean(predicted),
se=mean(se), bias=mean(observed-predicted)/se))
df4 <- as.data.frame(df4 %>% group_by(month=month(df4$date)) %>%
summarise(observed=mean(observed), predicted=mean(predicted),
se=mean(se), bias=mean(observed-predicted)/se))
df1$method <- 'PCA-clustered'
df2$method <- 'Basin-clustered'
df3$method <- 'One-clustered'
df4$method <- 'Watershed-level'
df <- rbind(df1,df2, df3, df4)
names(df) <- c('month', 'observed', 'predicted', 'Uncertainty','SR', 'method')
cols <- c("red", "blue")
if(best == 1){
df <- df1
}else if(best == 2){df <- df2}
else if(best == 2){df <- df3}
else{df==df4}
p <- ggplot(df, aes(x=month, y=SR)) +
scale_colour_manual(name="Methods", values=cols,limits=c(unique(df$method),'Bias-adjusted')) +
geom_point(aes(colour = method), size=2.5)+
theme_bw()+theme(legend.position = "none")+ggtitle(shed_name)+
scale_x_continuous("Month", breaks=c(1:12)) +
scale_y_continuous("Standardized residuals",limits=c(-2.2,2.2)) +
geom_hline(yintercept=0, linetype="dashed", color = "red", size=0.75) +
theme(axis.title.x=element_blank(),
axis.title.y=element_blank(),
axis.ticks.x=element_blank(),
text = element_text(size=15))
return(p)
}
BoxPlt1 <- function(df1,df2,df3,df4,shed_name,){
df1 <- as.data.frame(df1 %>% group_by(month=month(df1$date)) %>%
summarise(observed=mean(observed), predicted=mean(predicted),
se=mean(se), bias=mean(observed-predicted)/se,
bias_bc=mean(observed-predicted_bc)/se))
df2 <- as.data.frame(df2 %>% group_by(month=month(df2$date)) %>%
summarise(observed=mean(observed), predicted=mean(predicted),
se=mean(se), bias=mean(observed-predicted)/se))
df3 <- as.data.frame(df3 %>% group_by(month=month(df3$date)) %>%
summarise(observed=mean(observed), predicted=mean(predicted),
se=mean(se), bias=mean(observed-predicted)/se))
df4 <- as.data.frame(df4 %>% group_by(month=month(df4$date)) %>%
summarise(observed=mean(observed), predicted=mean(predicted),
se=mean(se), bias=mean(observed-predicted)/se))
df1$method <- 'PCA-clustered'
df2$method <- 'Basin-clustered'
df3$method <- 'One-clustered'
df4$method <- 'Watershed-level'
df <- rbind(df1,df2, df3, df4)
names(df) <- c('month', 'observed', 'predicted', 'Uncertainty','SR', 'method')
cols <- c("red", "blue")
if(best == 1){
df <- df1
}
else if(best == 2){df <- df2}
else if(best == 3){df <- df3}
else{df==df4}
p <- ggplot(df, aes(x=month, y=SR)) +
scale_colour_manual(name="Methods", values=cols,limits=c(unique(df$method),'Bias-adjusted')) +
geom_point(aes(colour = method), size=2.5)+
theme_bw()+theme(legend.position = "none")+ggtitle(shed_name)+
scale_x_continuous("Month", breaks=c(1:12)) +
scale_y_continuous("Standardized residuals",limits=c(-2.2,2.2)) +
geom_hline(yintercept=0, linetype="dashed", color = "red", size=0.75) +
theme(axis.title.x=element_blank(),
axis.title.y=element_blank(),
axis.ticks.x=element_blank(),
text = element_text(size=15))
return(p)
}
BoxPlt1 <- function(df1,df2,df3,df4,shed_name,best){
df1 <- as.data.frame(df1 %>% group_by(month=month(df1$date)) %>%
summarise(observed=mean(observed), predicted=mean(predicted),
se=mean(se), bias=mean(observed-predicted)/se,
bias_bc=mean(observed-predicted_bc)/se))
df2 <- as.data.frame(df2 %>% group_by(month=month(df2$date)) %>%
summarise(observed=mean(observed), predicted=mean(predicted),
se=mean(se), bias=mean(observed-predicted)/se,
bias_bc=mean(observed-predicted_bc)/se))
df3 <- as.data.frame(df3 %>% group_by(month=month(df3$date)) %>%
summarise(observed=mean(observed), predicted=mean(predicted),
se=mean(se), bias=mean(observed-predicted)/se,
bias_bc=mean(observed-predicted_bc)/se))
df4 <- as.data.frame(df4 %>% group_by(month=month(df4$date)) %>%
summarise(observed=mean(observed), predicted=mean(predicted),
se=mean(se), bias=mean(observed-predicted)/se,
bias_bc=mean(observed-predicted_bc)/se))
df1$method <- 'PCA-clustered'
df2$method <- 'Basin-clustered'
df3$method <- 'One-clustered'
df4$method <- 'Watershed-level'
df <- rbind(df1,df2, df3, df4)
names(df) <- c('month', 'observed', 'predicted', 'Uncertainty','SR', 'method')
cols <- c("red", "blue")
if(best == 1){
df <- df1
}
else if(best == 2){df <- df2}
else if(best == 3){df <- df3}
else{df==df4}
p <- ggplot(df, aes(x=month, y=SR)) +
scale_colour_manual(name="Methods", values=cols,limits=c(unique(df$method),'Bias-adjusted')) +
geom_point(aes(colour = method), size=2.5)+
theme_bw()+theme(legend.position = "none")+ggtitle(shed_name)+
scale_x_continuous("Month", breaks=c(1:12)) +
scale_y_continuous("Standardized residuals",limits=c(-2.2,2.2)) +
geom_hline(yintercept=0, linetype="dashed", color = "red", size=0.75) +
theme(axis.title.x=element_blank(),
axis.title.y=element_blank(),
axis.ticks.x=element_blank(),
text = element_text(size=15))
return(p)
}
best <- c(1,1,1,2,3,1,1,1,1,2,3,1,2,3,3,3,3,1,1,2)
best <- c(1,1,1,2,3,1,1,1,1,2,3,1,2,3,3,3,3,1,1,1,2)
df.all=all.df1
df.pca=pca.df1
df.shed=shed.df1
df.basin=basin.df1
BoxPlt1 <- function(df1,df2,df3,df4,shed_name,best){
df1 <- as.data.frame(df1 %>% group_by(month=month(df1$date)) %>%
summarise(observed=mean(observed), predicted=mean(predicted),
se=mean(se), bias=mean(observed-predicted)/se,
bias_bc=mean(observed-predicted_bc)/se))
df2 <- as.data.frame(df2 %>% group_by(month=month(df2$date)) %>%
summarise(observed=mean(observed), predicted=mean(predicted),
se=mean(se), bias=mean(observed-predicted)/se,
bias_bc=mean(observed-predicted_bc)/se))
df3 <- as.data.frame(df3 %>% group_by(month=month(df3$date)) %>%
summarise(observed=mean(observed), predicted=mean(predicted),
se=mean(se), bias=mean(observed-predicted)/se,
bias_bc=mean(observed-predicted_bc)/se))
df4 <- as.data.frame(df4 %>% group_by(month=month(df4$date)) %>%
summarise(observed=mean(observed), predicted=mean(predicted),
se=mean(se), bias=mean(observed-predicted)/se,
bias_bc=mean(observed-predicted_bc)/se))
df1$method <- 'PCA-clustered'
df2$method <- 'Basin-clustered'
df3$method <- 'One-clustered'
df4$method <- 'Watershed-level'
df <- rbind(df1,df2, df3, df4)
names(df) <- c('month', 'observed', 'predicted', 'Uncertainty','SR', 'method')
cols <- c("red", "blue")
if(best == 1){
df <- df1
}
else if(best == 2){df <- df2}
else if(best == 3){df <- df3}
else{df==df4}
p <- ggplot(df, aes(x=month, y=SR)) +
scale_colour_manual(name="Methods", values=cols,limits=c(unique(df$method),'Bias-adjusted')) +
geom_point(aes(colour = method), size=2.5)+
theme_bw()+theme(legend.position = "none")+ggtitle(shed_name)+
scale_x_continuous("Month", breaks=c(1:12)) +
scale_y_continuous("Standardized residuals",limits=c(-2.2,2.2)) +
geom_hline(yintercept=0, linetype="dashed", color = "red", size=0.75) +
theme(axis.title.x=element_blank(),
axis.title.y=element_blank(),
axis.ticks.x=element_blank(),
text = element_text(size=15))
return(p)
}
best <- c(1,1,1,2,3,1,1,1,1,2,3,1,2,3,3,3,3,1,1,1,2)
boxplt <- lapply(1:21, function(x) BoxPlt1(df.pca[[x]], df.basin[[x]], df.all[[x]],
df.shed[[x]],SW.list[[x]], best[[x]]))
ggsave( multiplot(boxplt[[1]], boxplt[[2]],boxplt[[3]], boxplt[[4]], boxplt[[5]],
boxplt[[6]], boxplt[[7]],boxplt[[8]], boxplt[[9]], boxplt[[10]],
boxplt[[11]], boxplt[[12]],boxplt[[13]], boxplt[[14]], boxplt[[15]],
boxplt[[16]], boxplt[[17]],boxplt[[18]], boxplt[[19]], boxplt[[20]],
boxplt[[21]],cols=3),filename='PaperFigure_BiasShed.png',device='png',
dpi=600, width = 8, height = 16, units='in' )
